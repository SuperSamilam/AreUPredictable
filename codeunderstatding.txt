get data function simple

A layer is a layer in a machine learning
A dence layer is a layer where are prevoicly neurns connects to all other neruns and everything like that
it consitsits of weights, biases, forward passes and backward passes
weights är ett värde varje neutron har för att definera hur mycket den påverkar
biases efter varje weight har gjort sitt lägger den till en bias som också är individuell för varje neutron
Forward pass är när man lägger in datan och den kalkyleras
Backward passes används senare för att justera vikterna i ML för att kunna få ett bättre resultat senare

ReLU Rectified Liner unit
Vad relus gör är att dom funkar som som abs

Softmax converst logist to probebiltis

Loss is how much of the predictionas were wrong

Loss class entory do the same as loss kinda

Optemizers are used top adjust weights and biases to imporve the loss function

Gradiants are the type of optimizer

SGD
SGD uses only a small point or a small batch of the dataset to update everhything

Adagrad
It uses prevois parametss the adapt the learnintg reate ussaly gets slower with time
Formulat som används oftast är
0 = 0 - (n/roten av(g+c)) *0*L
där 0 är det tidigar3e resultatet, n start learning rate, g summan av alla sqwuares, L loss grqadienet

RMSProp
Root mean squared propagation
it adjusts the avarage based on reacent graidents, makes the learning rate stay more constitant

Adam
Adaptive moment Estimation
Adapsts the learning rate for each parameter useing the mean of the gradient 

ITS WEIRD